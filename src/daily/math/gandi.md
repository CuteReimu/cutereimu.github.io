---
title: 名侦探甘迪问题
icon: question
order: 2
category: 数学
tags:
  - 信息熵
  - TypeScript
---

一切的一切，要源于《冒险岛Online》在2018年推出的一个小游戏——名侦探甘迪：

> 游戏开始时，会将一群玩家传送进同一个房间。此时，会在1-9九个数字中随机选择三个数字按某个顺序排列，作为答案。
>
> 每一轮，玩家需要按顺序猜测3个数字，系统会给出反馈，告知玩家有几个数字猜对了并且位置正确（用○表示），有几个数字猜对了但位置不正确（用△表示）。
>
> 举个例子：玩家猜测1-2-3三个数字，系统给出反馈1○1△，表示有一个数字猜对了并且位置正确，有一个数字猜对了但位置不正确。可能是1猜对了且位置正确，2猜对了但位置不正确，答案中没有3，当然也有别的可能。
> 
> 玩家可以根据反馈来继续推测答案。玩家不能看到其它玩家的选择及反馈。所有玩家互为竞争对手，目标就是用最少的次数猜出答案。

我们的问题就来了，如何设计策略，让我们在尽可能少的次数内猜出答案呢？

这是一个十分经典的策略问题。

<!-- more -->

## 信息熵

信息熵是信息论中的一个核心概念，由克劳德·香农（Claude Shannon）于1948年提出，用于**量化信息的不确定性**或**随机性**。它衡量的是一个系统或随机事件中“不可预测性”的程度。

### 信息熵的直观理解

想象你面对一个未知的结果（例如抛硬币、天气预报、猜数字游戏）：
- **熵高**：结果难以预测，不确定性大。*（例如：公平的硬币，正反面概率各50%）*
- **熵低**：结果容易预测，不确定性小。*（例如：一枚作弊了的硬币，正面概率99%，反面1%）*

**信息熵的数值越大，系统越混乱；数值越小，系统越确定**。

### 信息熵的数学定义

信息熵的公式为：
$$
H(X) = -\sum_{i=1}^{n} P(x_i) \log_2 P(x_i)
$$

**符号解释**：
- $X$：一个随机变量（例如天气、抛硬币的结果）。
- $P(x_i)$：事件$x_i$发生的概率（例如“晴天”的概率是0.3）。
- $\log_2$：以2为底的对数，单位是**比特（bit）**（也可用自然对数，单位是纳特）。

信息熵有这样一些性质：
- **不确定性最大**：当所有可能事件的概率相等时，熵最大。*（例如：公平骰子的熵 > 作弊骰子的熵）*
- **确定性最小**：当某个事件概率为1时，熵为0。*（例如：作弊硬币总是正面 &rarr; 熵=0）*

我们还是用抛硬币的例子来说明：
- **公平硬币**：正面概率0.5，反面概率0.5  
  $$
  H = -0.5 \log_2 0.5 -0.5 \log_2 0.5 = 1 \text{ bit}
  $$
- **作弊硬币**：正面概率0.99，反面概率0.01  
  $$
  H \approx -0.99 \log_2 0.99 -0.01 \log_2 0.01 \approx 0.08 \text{ bits}
  $$

## 最大化信息熵策略

让我们回到名侦探甘迪问题。在这个游戏中，我们的目标是**最快缩小答案范围**，就应该使用**最大化信息熵**策略。

为什么要用**最大化信息熵**策略呢？

我们进行一次猜测后，会得到一个反馈（如1○1△、0○2△等）。假设我们猜三个几乎不可能的数字，反馈0○0△的概率很高，达到90%以上，这个猜测就没有什么意义，我们从反馈中也无法得到多少有用的信息。而如果我们的猜测，使得反馈结果的概率分布尽可能均匀（即每种反馈的概率都差不多），也就是信息熵最大的策略，那么我们就能从反馈中获得更多的信息。

举个例子，首轮我们猜测1-2-3，得到1○1△的反馈。我们可以排除大部分可能性，还剩下36种可能（1-3-4、1-3-5、1-3-6、……、9-2-1）。接下来，我们依次计算每种猜测的信息熵。举两个例子：

- 猜测1-4-5，可能的反馈有：
  - 0○0△：有8种可能，概率为8/36
  - 0○1△：有10种可能，概率为10/36
  - 0○2△：有4种可能，概率为4/36
  - 1○0△：有10种可能，概率为10/36
  - 1○1△：有2种可能，概率为2/36
  - 2○0△：有2种可能，概率为2/36
  
  因此信息熵为：
  $$
  H = -\left(\dfrac{8}{36} \log_2 \dfrac{8}{36} + \dfrac{10}{36} \log_2 \dfrac{10}{36} + \dfrac{4}{36} \log_2 \dfrac{4}{36} + \dfrac{10}{36} \log_2 \dfrac{10}{36} + \dfrac{2}{36} \log_2 \dfrac{2}{36} + \dfrac{2}{36} \log_2 \dfrac{2}{36}\right) \approx 2.32 \text{ bits}
  $$
- 猜测4-5-6，可能的反馈有：
  - 0○0△：有18种可能，概率为18/36
  - 0○1△：有12种可能，概率为12/36
  - 1○0△：有6种可能，概率为6/36

  因此信息熵为：
  $$
  H = \left(\dfrac{18}{36} \log_2 \dfrac{18}{36} + \dfrac{12}{36} \log_2 \dfrac{12}{36} + \dfrac{6}{36} \log_2 \dfrac{6}{36}\right) \approx 1.46 \text{ bits}
  $$

前者比后者的信息熵更大，因此我们选择前者进行猜测更优。

以上只列举了两种猜测的例子，我们只需要遍历所有的猜测（一共$A_9^3=504$种），计算每种猜测的信息熵，选择信息熵最大的进行猜测即可。

### 代码实现

```ts :no-collapsed-lines
// compare 函数用于比较两个结果的差异，返回○和△值
const compare = (result1: number[], result2: number[]): [number, number] => {
    let count1 = 0;
    let count2 = 0;
    for (let i = 0; i < result1.length; i++) {
        for (let j = 0; j < result2.length; j++) {
            if (result1[i] === result2[j]) {
                if (i === j) count1++;
                else count2++;
            }
        }
    }
    return [count1, count2];
};

// 首轮猜测1-2-3，反馈1○1△
const maybeResult: [number, number, number][] = [];
for (let a = 1; a <= 9; a++) {
    for (let b = 1; b <= 9; b++) {
        for (let c = 1; c <= 9; c++) {
            if (a === b || a === c || b === c) continue;
            const [count1, count2] = compare([1, 2, 3], [a, b, c]);
            if (count1 === 1 && count2 === 1) maybeResult.push([a, b, c]);
        }
    }
} // 这时 maybeResult 应该只有36种可能

let maxH = 0.0; // 最大信息熵
let maxHResults: [number, number, number][] = []; // 最大信息熵对应的选项
// 计算每种猜测的信息熵
for (let a = 1; a <= 9; a++) {
    for (let b = 1; b <= 9; b++) {
        for (let c = 1; c <= 9; c++) {
            if (a === b || a === c || b === c) continue;
            const counts = {}; // 统计每种反馈的出现次数
            for (const i in maybeResult) {
                const [count1, count2] = compare([a, b, c], maybeResult[i]);
                counts[`${count1},${count2}`] = (counts[`${count1},${count2}`] || 0) + 1;
            }
            let H = 0; // 信息熵
            for (const i in counts) {
                const p = counts[i] / maybeResult.length;
                H -= p * Math.log2(p);
            }
            if (Math.abs(H - maxH) < 0.0001) { // 浮点数精度
                maxHResults.push([a, b, c]);
            } else if (H > maxH) {
                maxH = H;
                maxHResults = [[a, b, c]];
            }
        }
    }
}

console.log(maxH);
console.log(maxHResults);
```

上面的代码可以得到这样的结果：在第一轮得到1○1△的反馈后，只需要固定一个数字作为1○，并从4~9中选择另外两个数字进行猜测，就可以获得最大信息熵，约为2.32。上文列举的1-4-5即为其中之一猜测方案。

接下来，我们每一轮只需要根据反馈缩小可能的范围，再遍历一次找到最大信息熵，这就是**最大化信息熵**的策略。